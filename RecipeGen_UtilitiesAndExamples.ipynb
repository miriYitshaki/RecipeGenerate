{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecipeGen_UtilitiesAndExamples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRv_FynsVSR3",
        "colab_type": "text"
      },
      "source": [
        "# Enviroment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0GZkUITVikS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78e0db03-218a-4b76-d2c1-b30ea1775885"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogTke7mSMMI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "df81d1b2-9013-4dc2-94b0-7535509a687c"
      },
      "source": [
        "%cd\n",
        "%cd /content/drive/Shared\\ drives/rs/RSProject/recipe-personalization_org/\n",
        "#%cd /content/drive/Shared\\ drives/rs/RSProject/recipe-personalization/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content/drive/Shared drives/rs/RSProject/recipe-personalization_org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFf1EnwmMYrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2fb567dd-740f-4545-d10d-1200f6146c67"
      },
      "source": [
        "! git clone https://github.com/majumderb/recipe-personalization.git\n",
        "#%cd recipe-personalization/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'recipe-personalization'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 128 (delta 63), reused 92 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (128/128), 77.37 KiB | 720.00 KiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOOZ2FHMm6kC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "outputId": "e95ae4f8-4b96-4f57-b6cb-2902ee77be31"
      },
      "source": [
        "#PyTorch\n",
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip3 install torchvision\n",
        "!pip install pytorch-pretrained-bert\n",
        "!pip install pyrouge\n",
        "import torch\n",
        "#gpu enabling\n",
        "use_cuda = False\n",
        "#if use_cuda and torch.cuda.is_available():\n",
        " # print (\"using GPU\")\n",
        "#    net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (663.1MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1MB 28kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 57.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2.0+cu92) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0+cu92)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.2.0+cu92)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.15.0)\n",
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.33)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.2.0+cu92)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.33)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Collecting pyrouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/85/e522dd6b36880ca19dcf7f262b22365748f56edc6f455e7b6a37d0382c32/pyrouge-0.1.3.tar.gz (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-cp36-none-any.whl size=191613 sha256=9615869fb8dab65dd7620833b028f7270ead2fe76557c25fc79c87e6c098b130\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d3/0c/e5b04e15b6b87c42e980de3931d2686e14d36e045058983599\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dQN3eafQ7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8efb1db5-0ab0-4e3d-db45-0c77bd21b16b"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Shared_with_me/recipe-personalization_org/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Shared_with_me/recipe-personalization_org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ0fqRGmUKY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "977d04f6-0f56-450c-d632-7ddbce147ca8"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import recipe_gen\n",
        "from recipe_gen import *\n",
        "from recipe_gen import utils\n",
        "from recipe_gen import analysis\n",
        "from recipe_gen import pipeline\n",
        "import recipe_gen.language\n",
        "import recipe_gen.utils\n",
        "import recipe_gen.pipeline\n",
        "import recipe_gen.analysis\n",
        "from recipe_gen.pipeline import *\n",
        "from recipe_gen.analysis import *\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 815973/815973 [00:01<00:00, 635559.35B/s]\n",
            "100%|██████████| 458495/458495 [00:00<00:00, 530961.57B/s]\n",
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxCb61zKHF4U",
        "colab_type": "text"
      },
      "source": [
        "Prepering input files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR6lXqasAtuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modified_PP_recipes\n",
        "df = pd.read_csv('/content/drive/My Drive/Shared_with_me/recipe-personalization_org/Data/recipe_reduced_ingr.csv', engine='c')\n",
        "for col in ['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']:\n",
        "    df[col] = df[col].agg(eval)\n",
        "df.to_pickle('/content/drive/My Drive/Shared_with_me/recipe-personalization_org/DataTempEval/recipes.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJOFmxGwNbhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Files creation: run only ONCE!\n",
        "# No need to Run\n",
        "import pandas as pd\n",
        "\n",
        "interactions_train = pd.read_csv(\"Data/interactions_train.csv\",nrows=1000)\n",
        "interactions_train.to_pickle(\"DataTemp/interactions_train.pkl\")\n",
        "interactions_test = pd.read_csv(\"Data/interactions_test.csv\")\n",
        "interactions_test.to_pickle(\"DataTemp/interactions_test_new.pkl\")\n",
        "interactions_test = pd.read_csv(\"Data/interactions_test.csv\")\n",
        "interactions_test.to_pickle(\"DataTemp/interactions_test.pkl\")\n",
        "PP_u = pd.read_csv(\"Data/PP_users.csv\")\n",
        "PP_u.to_pickle(\"DataTemp/user_rep.pkl\")\n",
        "interactions_valid_new = pd.read_csv(\"Data/interactions_validation.csv\")\n",
        "interactions_valid_new.to_pickle(\"DataTemp/interactions_valid_new.pkl\")\n",
        "df = pd.read_csv('Data/PP_recipes.csv', engine='c')\n",
        "for col in ['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']:\n",
        "    df[col] = df[col].agg(eval)\n",
        "df.to_pickle('DataTemp/recipes.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMr0Kr-jLuM8",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFx4CPXB-Buc",
        "colab_type": "text"
      },
      "source": [
        "train on original pp_recipes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHdTlQp97pwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -u -m recipe_gen.models.baseline.train --data-dir DataTemp/ --batch-size 32 --vocab-emb-size 300 --calorie-emb-size 5 --nhid 256 --nlayers 2 --lr 1e-3 --epochs 1 --annealing-rate 0.9 --save OUTPUT3K/ --ingr-emb --ingr-gru --exp-name baseline\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHlRPQzvGWcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -u -m recipe_gen.models.user_nutri_pref.train --data-dir DataTemp50K/ --batch-size 38 --vocab-emb-size 300 --tech-emb-size 50 --calorie-emb-size 6 --nhid 256 --nlayers 2 --lr 1e-3 --epochs 7 --annealing-rate 0.9 --save OUTPUT50FNutri/ --ingr-emb --ingr-gru --exp-name usernutri\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZGw7LP1IG4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -u -m recipe_gen.models.user_technique_pref.train --data-dir DataTemp/ --batch-size 32 --vocab-emb-size 300 --tech-emb-size 50 --calorie-emb-size 5 --nhid 256 --nlayers 2 --lr 1e-3 --epochs 1 --annealing-rate 0.9 --save OUTPUTT/ --ingr-emb --ingr-gru --exp-name tech_pref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axVJXqPL-DGk",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwWgh8--f5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this one:\n",
        "#just set OUTPUT/model_baseline_e0.pt to the currect model file\n",
        "!python3 -m recipe_gen.models.baseline.test --data-dir DataTemp/ --model-path OUTPUT12KBH/model_baseline_e4.pt --vocab-emb-size 300 --calorie-emb-size 5 --nhid 256 --nlayers 2 --ingr-emb --ingr-gru --ingr-emb-size 10 --save-dir OUTPUT12KBH/ --batch-size 32\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKc2AoEoGfk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !python3 -u -m recipe_gen.models.user_nutri_pref.test --data-dir DataModified/ --model-path OUTPUT50FNutri/model_usernutri_eX.pt --batch-size 38 --vocab-emb-size 300  --calorie-emb-size 6 --nhid 256 --nlayers 2 --ingr-emb --ingr-gru --ingr-emb-size 10 --save-dir OUTPUT50FNutri/ --batch-size 36 --ingr-gru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEPfU-01DCHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7df808a2-6b0d-4597-ead9-4424c52088ef"
      },
      "source": [
        "!python -m recipe_gen.models.user_technique_pref.test --data-dir DataTempEval/ --model-path OUTPUTEvalTch/model_tech_pref_e2.pt --vocab-emb-size 300 --tech-emb-size 50 --calorie-emb-size 5 --nhid 256 --nlayers 2 --save-dir OUTPUTEvalTch/ --ingr-gru --ingr-emb --overwrite --batch-size 48\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Device: cuda:0\n",
            "Using CUDA 0\n",
            "0:00:00.062764 - Loaded 11,996 training interactions, 7,023 validation, 10 test (2.034 MB total memory)\n",
            "0:00:00.322293 - Loaded items for 25,076 users, 6,437 maximum interactions/user (31.008 MB total memory)\n",
            "0:00:06.609838 - Loaded 178,265 recipes (364.728 MB total memory)\n",
            "0:00:06.715497 - Loaded map for 8,024 unique ingredients\n",
            "0:00:06.756007 - Data loaded.\n",
            "INGR EMBEDDING\n",
            "0:00:00.802490 - Padded names to maximum 15 tokens\n",
            "0:00:01.976910 - Padded steps to maximum 256 tokens\n",
            "0:00:03.338434 - Clipped ingredients randomly between 3 and 5 incidents\n",
            "0:00:06.203272 - Padded ingredients to maximum 20 tokens and 5 ingredients\n",
            "0:00:07.476590 - Padded ingredient IDs to maximum 5 ingredients w pad ingredient 8023\n",
            "0:00:09.144232 - Processed techniques and the associated masks\n",
            "0:00:00.209090 - Sorted recipes DF by recipe ID\n",
            "name_tokens:        178,265 x 15    (20.401 MB)\n",
            "calorie_level:      178,265         (1.360 MB)\n",
            "techniques:         178,265 x 45    (61.202 MB)\n",
            "ingredient_ids:     178,265 x 5     (6.800 MB)\n",
            "steps_tokens:       178,265 x 256   (348.174 MB)\n",
            "ingredient_id_mask: 178,265 x 5     (6.800 MB)\n",
            "techniques_mask:    178,265 x 45    (61.202 MB)\n",
            "0:00:07.596798 - Loaded tensors to GPU - TOTAL 505.940 MB\n",
            "0:00:23.563930 - Tensors loaded in memory.\n",
            "Loaded dataset with 10 rows\n",
            "Every epoch, we have 1 48-sized batches for a total of 10 instances\n",
            "Created encoder with 256 hidden size, 2-layer BiGRU ingredient encoding, 1,280 output size\n",
            "Creating decoder with 256 layers of size 2 with 0.000 dropout\n",
            "Encoded ingredients size 512, encoded name size 512, encoded calorie size 256\n",
            "0:00:00.225835 - Constructed model skeleton\n",
            "0:00:00.411825 - Created PersonalTechEncoderDecoder model with 28,595,543 parameters\n",
            "PersonalTechEncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (vocab_embedding): Embedding(40483, 300)\n",
            "    (calorie_embedding): Embedding(5, 5)\n",
            "    (ingr_embedding): Embedding(8024, 10)\n",
            "    (name_encoder): GRU(300, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (calorie_encoder): Sequential(\n",
            "      (0): Linear(in_features=5, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (ingr_encoder): GRU(10, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (decoder): PersonalTechDecoder(\n",
            "    (vocab_embedding): Embedding(40483, 300)\n",
            "    (proj): Linear(in_features=256, out_features=40483, bias=False)\n",
            "    (technique_embedding): Embedding(45, 50)\n",
            "    (prior_tech_key_projection): Linear(in_features=50, out_features=256, bias=True)\n",
            "    (prior_tech_attention): BahdanauAttention(\n",
            "      (key_layer): Linear(in_features=256, out_features=256, bias=False)\n",
            "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
            "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
            "    )\n",
            "    (ingr_attention): BahdanauAttention(\n",
            "      (key_layer): Linear(in_features=512, out_features=256, bias=False)\n",
            "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
            "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
            "    )\n",
            "    (attn_fusion_layer): Sequential(\n",
            "      (0): Linear(in_features=1886, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (rnn): GRU(812, 256, num_layers=2, batch_first=True)\n",
            "  )\n",
            "  (bridge_layer): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.26s/it]\n",
            "\n",
            "Name Perplexity: 1.0\n",
            "PERPLEXITY: 14.25412\n",
            "Saved generation DF to OUTPUTEvalTch/model_tech_pref_e2/generated_df.pkl\n",
            "    u  ...  n_techniques\n",
            "0   2  ...             0\n",
            "1  16  ...             0\n",
            "2  26  ...             0\n",
            "\n",
            "[3 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FaHij73vI6x",
        "colab_type": "text"
      },
      "source": [
        "Review some output examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdYZAyas8YJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1e1e0583-552a-4f59-8e20-22fda6c01b54"
      },
      "source": [
        "!cat \"/content/drive/My Drive/Shared_with_me/recipe-personalization_org/OUTPUT50KBH/model_baseline_e2/test_i173538_u2/output.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ORIGINAL NAME: `strawberry fudge |END|`\n",
            "Calorie-Level: `Low-Calorie`\n",
            "Techniques:\n",
            "--boil\n",
            "--combine\n",
            "--pour\n",
            "Ingredients:\n",
            "--sugar\n",
            "--strawberry gelatin\n",
            "--salt\n",
            "--milk\n",
            "--half-and-half\n",
            "\n",
            "Original Steps:\n",
            "combine first 6 ingredients in a buttered 3 - quart heavy sauce pan . bring mixture to a boil over medium heat , stirring constantly . cook without stirring until candy thermometer reaches 230f . or until it makes a soft ball when tested in cold water . remove from heat . add margarine or butter and vanilla , do not stir ! . cool without stirring until outside of pan becomes lukewarm . stir in nuts and beat until candy loses its gloss . pour into 3 dozen paper bonbon cups . |END|\n",
            "\n",
            "MODEL OUTPUT:\n",
            "combine sugar , milk , and salt in a large saucepan and bring to boil , stirring constantly . boil , stirring occasionally , until mixture comes to a boil . stir in cream and vanilla . bring to a boil , then reduce heat and simmer for 10 minutes . remove from heat and stir in vanilla . pour into a greased 8 inch square pan . sprinkle with remaining 1 / 4 cup of the remaining chocolate . sprinkle with 1 / 2 cup of the walnuts . cover and refrigerate overnight . to serve , remove from pan . cut into squares . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tHrwLSR8lYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "a8089900-08c3-49a0-e986-9afd98d2bf71"
      },
      "source": [
        "!cat \"/content/drive/My Drive/Shared_with_me/recipe-personalization_org/OUTPUTEvalTch/model_tech_pref_e2/test_i173538_u2/output.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ORIGINAL NAME: `strawberry fudge |END|`\n",
            "Calorie-Level: `Low-Calorie`\n",
            "Techniques:\n",
            "--c0\n",
            "--s9\n",
            "--f0\n",
            "--n0\n",
            "Ingredients:\n",
            "--sugar\n",
            "--strawberry gelatin\n",
            "--salt\n",
            "--milk\n",
            "--half-and-half\n",
            "\n",
            "Original Steps:\n",
            "combine first 6 ingredients in a buttered 3 - quart heavy sauce pan . bring mixture to a boil over medium heat , stirring constantly . cook without stirring until candy thermometer reaches 230f . or until it makes a soft ball when tested in cold water . remove from heat . add margarine or butter and vanilla , do not stir ! . cool without stirring until outside of pan becomes lukewarm . stir in nuts and beat until candy loses its gloss . pour into 3 dozen paper bonbon cups . |END|\n",
            "\n",
            "MODEL OUTPUT:\n",
            "combine sugar and milk in a large bowl . add 1 / 2 cup sugar , 2 tbsp vanilla , 1 / 2 cup sugar , and 2 tablespoons water . beat until well combined , about 3 minutes . add vanilla and vanilla . beat until smooth . pour into a greased 13x9 pan . bake at 350f for 30 minutes . cool in pan on a wire rack . refrigerate . to make ahead : in a small saucepan , bring 1 cup of sugar and 1 / 2 teaspoons sugar to boil . stir in vanilla and stir . pour over chocolate mixture , and let stand until chocolate chips are melted . serve warm . enjoy ! . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYWleTQp-GXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d506e6ac-6c14-42ce-afb4-2a9bf2010005"
      },
      "source": [
        "!cat \"/content/drive/My Drive/Shared_with_me/recipe-personalization_org/OUTPUT50KBH/model_baseline_e2/test_i177847_u16/output.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ORIGINAL NAME: `azumaya pot stickers |END|`\n",
            "Calorie-Level: `Low-Calorie`\n",
            "Techniques:\n",
            "--combine\n",
            "--simmer\n",
            "--skillet\n",
            "Ingredients:\n",
            "--ground lean pork\n",
            "--cabbage\n",
            "--water chestnut\n",
            "--scallion\n",
            "\n",
            "Original Steps:\n",
            "combine meat or tofu and cabbage , water chestnuts , green onions , ginger , soy sauce and salt in a bowl and mix well . place one teaspoon of filling in each wrap , fold and seal edges , turn pot sticker seam side up , then set down firmly on a flat surface to create a flat bottom . divide potstickers into 3 batches and cook each batch as follows . heat 2 teaspoons oil in a large nonstick skillet . brown bottoms of potstickers . add 1 cup of broth , cover skillet and let simmer 10 minutes . uncoverand cook until all liquid is absorbed . remove and serve with dipping sauces . |END|\n",
            "\n",
            "MODEL OUTPUT:\n",
            "in a small sauce pan , heat oil , add the garlic , and stir to cook . add the garlic and saut until the onions begin to soften . add the garlic and cook until the garlic is softened , about 5 minutes . add the chicken and cook until the bottoms are no longer pink , about 5 minutes . add the garlic and cook for 5 to 10 minutes , until the garlic is tender and the mixture is no longer pink . drain the fat and add to the sauce . stir in the cilantro and stir in the remaining ingredients . cover and simmer on high for about 5 minutes . serve over hot rice , and enjoy ! . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCErFA4n-N3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "791201da-a474-49c5-cb62-668d597595ee"
      },
      "source": [
        "!cat \"/content/drive/My Drive/Shared_with_me/recipe-personalization_org/OUTPUTEvalTch/model_tech_pref_e2/test_i177847_u16/output.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ORIGINAL NAME: `azumaya pot stickers |END|`\n",
            "Calorie-Level: `Low-Calorie`\n",
            "Techniques:\n",
            "--c0\n",
            "--s0\n",
            "--f0\n",
            "--n1\n",
            "Ingredients:\n",
            "--ground lean pork\n",
            "--cabbage\n",
            "--water chestnut\n",
            "--scallion\n",
            "\n",
            "Original Steps:\n",
            "combine meat or tofu and cabbage , water chestnuts , green onions , ginger , soy sauce and salt in a bowl and mix well . place one teaspoon of filling in each wrap , fold and seal edges , turn pot sticker seam side up , then set down firmly on a flat surface to create a flat bottom . divide potstickers into 3 batches and cook each batch as follows . heat 2 teaspoons oil in a large nonstick skillet . brown bottoms of potstickers . add 1 cup of broth , cover skillet and let simmer 10 minutes . uncoverand cook until all liquid is absorbed . remove and serve with dipping sauces . |END|\n",
            "\n",
            "MODEL OUTPUT:\n",
            "place the chicken pieces in a large bowl , and stir in 1 tsp of water . add in the garlic , salt and pepper . add the remaining ingredients and stir well . add 1 tbsp of the butter to the pan . add the remaining ingredients , except for the chopped onions and stir to combine . add the chopped onions and serve immediately . serve with steamed rice , or rice . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfd5umyTdvCe",
        "colab_type": "text"
      },
      "source": [
        "Review model stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIXSNvwlFJCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "14fefee0-0393-4d44-af48-6ebe6f224a4b"
      },
      "source": [
        "\n",
        "df_stats = pd.read_pickle(\"ingredient_attention.pkl\")\n",
        "df_stats.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ingredient_attention.pkl  output.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>mix&lt;/w&gt;</th>\n",
              "      <th>the&lt;/w&gt;</th>\n",
              "      <th>first&lt;/w&gt;</th>\n",
              "      <th>seven&lt;/w&gt;</th>\n",
              "      <th>ingredients&lt;/w&gt;</th>\n",
              "      <th>in&lt;/w&gt;</th>\n",
              "      <th>a&lt;/w&gt;</th>\n",
              "      <th>small&lt;/w&gt;</th>\n",
              "      <th>bowl&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>mix&lt;/w&gt;</th>\n",
              "      <th>the&lt;/w&gt;</th>\n",
              "      <th>dressing&lt;/w&gt;</th>\n",
              "      <th>ingredients&lt;/w&gt;</th>\n",
              "      <th>together&lt;/w&gt;</th>\n",
              "      <th>and&lt;/w&gt;</th>\n",
              "      <th>mix&lt;/w&gt;</th>\n",
              "      <th>well&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>pour&lt;/w&gt;</th>\n",
              "      <th>mixture&lt;/w&gt;</th>\n",
              "      <th>into&lt;/w&gt;</th>\n",
              "      <th>the&lt;/w&gt;</th>\n",
              "      <th>prepared&lt;/w&gt;</th>\n",
              "      <th>pan&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>bake&lt;/w&gt;</th>\n",
              "      <th>at&lt;/w&gt;</th>\n",
              "      <th>400&lt;/w&gt;</th>\n",
              "      <th>degrees&lt;/w&gt;</th>\n",
              "      <th>for&lt;/w&gt;</th>\n",
              "      <th>20&lt;/w&gt;</th>\n",
              "      <th>minutes&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>serve&lt;/w&gt;</th>\n",
              "      <th>...</th>\n",
              "      <th>if&lt;/w&gt;</th>\n",
              "      <th>desired&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;/R&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>the&lt;/w&gt;</th>\n",
              "      <th>chicken&lt;/w&gt;</th>\n",
              "      <th>should&lt;/w&gt;</th>\n",
              "      <th>be&lt;/w&gt;</th>\n",
              "      <th>a&lt;/w&gt;</th>\n",
              "      <th>little&lt;/w&gt;</th>\n",
              "      <th>sticky&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;s&gt;</th>\n",
              "      <th>serve&lt;/w&gt;</th>\n",
              "      <th>over&lt;/w&gt;</th>\n",
              "      <th>the&lt;/w&gt;</th>\n",
              "      <th>chicken&lt;/w&gt;</th>\n",
              "      <th>,&lt;/w&gt;</th>\n",
              "      <th>lettuce&lt;/w&gt;</th>\n",
              "      <th>,&lt;/w&gt;</th>\n",
              "      <th>and&lt;/w&gt;</th>\n",
              "      <th>salsa&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;/R&gt;</th>\n",
              "      <th>and&lt;/w&gt;</th>\n",
              "      <th>a&lt;/w&gt;</th>\n",
              "      <th>good&lt;/w&gt;</th>\n",
              "      <th>football&lt;/w&gt;</th>\n",
              "      <th>of&lt;/w&gt;</th>\n",
              "      <th>black&lt;/w&gt;</th>\n",
              "      <th>olives&lt;/w&gt;</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;/R&gt;</th>\n",
              "      <th>chicken&lt;/w&gt;</th>\n",
              "      <th>,&lt;/w&gt;</th>\n",
              "      <th>a&lt;/w&gt;</th>\n",
              "      <th>few&lt;/w&gt;</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>plain yogurt</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.198283</td>\n",
              "      <td>0.111036</td>\n",
              "      <td>0.123241</td>\n",
              "      <td>0.221190</td>\n",
              "      <td>0.107316</td>\n",
              "      <td>0.079094</td>\n",
              "      <td>0.172799</td>\n",
              "      <td>0.175287</td>\n",
              "      <td>0.080974</td>\n",
              "      <td>0.093218</td>\n",
              "      <td>0.256074</td>\n",
              "      <td>0.240659</td>\n",
              "      <td>0.155391</td>\n",
              "      <td>0.107571</td>\n",
              "      <td>0.289098</td>\n",
              "      <td>0.169885</td>\n",
              "      <td>0.179096</td>\n",
              "      <td>0.169736</td>\n",
              "      <td>0.204865</td>\n",
              "      <td>0.137126</td>\n",
              "      <td>0.204240</td>\n",
              "      <td>0.252579</td>\n",
              "      <td>0.219682</td>\n",
              "      <td>0.214459</td>\n",
              "      <td>0.178143</td>\n",
              "      <td>0.102025</td>\n",
              "      <td>0.155745</td>\n",
              "      <td>0.239340</td>\n",
              "      <td>0.161714</td>\n",
              "      <td>0.251364</td>\n",
              "      <td>0.202284</td>\n",
              "      <td>0.131169</td>\n",
              "      <td>0.413893</td>\n",
              "      <td>0.284585</td>\n",
              "      <td>0.253028</td>\n",
              "      <td>0.314587</td>\n",
              "      <td>0.211146</td>\n",
              "      <td>0.240227</td>\n",
              "      <td>0.304192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231433</td>\n",
              "      <td>0.300028</td>\n",
              "      <td>0.156930</td>\n",
              "      <td>0.264176</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.131380</td>\n",
              "      <td>0.141916</td>\n",
              "      <td>0.332129</td>\n",
              "      <td>0.250301</td>\n",
              "      <td>0.286450</td>\n",
              "      <td>0.271067</td>\n",
              "      <td>0.285866</td>\n",
              "      <td>0.228575</td>\n",
              "      <td>0.323058</td>\n",
              "      <td>0.399875</td>\n",
              "      <td>0.258651</td>\n",
              "      <td>0.218137</td>\n",
              "      <td>0.323722</td>\n",
              "      <td>0.078102</td>\n",
              "      <td>0.046374</td>\n",
              "      <td>0.242830</td>\n",
              "      <td>0.232908</td>\n",
              "      <td>0.177457</td>\n",
              "      <td>0.246950</td>\n",
              "      <td>0.202368</td>\n",
              "      <td>0.135656</td>\n",
              "      <td>0.175653</td>\n",
              "      <td>0.090308</td>\n",
              "      <td>0.310652</td>\n",
              "      <td>0.174416</td>\n",
              "      <td>0.180883</td>\n",
              "      <td>0.243075</td>\n",
              "      <td>0.204525</td>\n",
              "      <td>0.219685</td>\n",
              "      <td>0.071697</td>\n",
              "      <td>0.225099</td>\n",
              "      <td>0.103066</td>\n",
              "      <td>0.072877</td>\n",
              "      <td>0.220816</td>\n",
              "      <td>0.241750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chicken breast</th>\n",
              "      <td>0.225498</td>\n",
              "      <td>0.381452</td>\n",
              "      <td>0.658146</td>\n",
              "      <td>0.357025</td>\n",
              "      <td>0.450031</td>\n",
              "      <td>0.521616</td>\n",
              "      <td>0.343188</td>\n",
              "      <td>0.315920</td>\n",
              "      <td>0.264330</td>\n",
              "      <td>0.115044</td>\n",
              "      <td>0.121517</td>\n",
              "      <td>0.132483</td>\n",
              "      <td>0.284299</td>\n",
              "      <td>0.349143</td>\n",
              "      <td>0.317631</td>\n",
              "      <td>0.361316</td>\n",
              "      <td>0.326182</td>\n",
              "      <td>0.195224</td>\n",
              "      <td>0.233853</td>\n",
              "      <td>0.459366</td>\n",
              "      <td>0.262255</td>\n",
              "      <td>0.184400</td>\n",
              "      <td>0.297586</td>\n",
              "      <td>0.313062</td>\n",
              "      <td>0.393282</td>\n",
              "      <td>0.318588</td>\n",
              "      <td>0.290250</td>\n",
              "      <td>0.337804</td>\n",
              "      <td>0.252479</td>\n",
              "      <td>0.284587</td>\n",
              "      <td>0.408389</td>\n",
              "      <td>0.171587</td>\n",
              "      <td>0.396456</td>\n",
              "      <td>0.265560</td>\n",
              "      <td>0.377782</td>\n",
              "      <td>0.530341</td>\n",
              "      <td>0.292639</td>\n",
              "      <td>0.126161</td>\n",
              "      <td>0.445625</td>\n",
              "      <td>0.238009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403599</td>\n",
              "      <td>0.214760</td>\n",
              "      <td>0.337959</td>\n",
              "      <td>0.460321</td>\n",
              "      <td>0.523617</td>\n",
              "      <td>0.569417</td>\n",
              "      <td>0.411213</td>\n",
              "      <td>0.183859</td>\n",
              "      <td>0.304250</td>\n",
              "      <td>0.339226</td>\n",
              "      <td>0.159950</td>\n",
              "      <td>0.290735</td>\n",
              "      <td>0.276616</td>\n",
              "      <td>0.158738</td>\n",
              "      <td>0.284208</td>\n",
              "      <td>0.403723</td>\n",
              "      <td>0.395219</td>\n",
              "      <td>0.233113</td>\n",
              "      <td>0.285934</td>\n",
              "      <td>0.225375</td>\n",
              "      <td>0.376602</td>\n",
              "      <td>0.250687</td>\n",
              "      <td>0.410227</td>\n",
              "      <td>0.390615</td>\n",
              "      <td>0.286973</td>\n",
              "      <td>0.378810</td>\n",
              "      <td>0.263196</td>\n",
              "      <td>0.378327</td>\n",
              "      <td>0.285825</td>\n",
              "      <td>0.242957</td>\n",
              "      <td>0.241509</td>\n",
              "      <td>0.227641</td>\n",
              "      <td>0.322636</td>\n",
              "      <td>0.243732</td>\n",
              "      <td>0.431096</td>\n",
              "      <td>0.405931</td>\n",
              "      <td>0.496519</td>\n",
              "      <td>0.522232</td>\n",
              "      <td>0.243305</td>\n",
              "      <td>0.357334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>white onion</th>\n",
              "      <td>0.602634</td>\n",
              "      <td>0.359718</td>\n",
              "      <td>0.223095</td>\n",
              "      <td>0.476557</td>\n",
              "      <td>0.221481</td>\n",
              "      <td>0.300188</td>\n",
              "      <td>0.545254</td>\n",
              "      <td>0.317220</td>\n",
              "      <td>0.160458</td>\n",
              "      <td>0.163533</td>\n",
              "      <td>0.067943</td>\n",
              "      <td>0.024011</td>\n",
              "      <td>0.048936</td>\n",
              "      <td>0.313986</td>\n",
              "      <td>0.467793</td>\n",
              "      <td>0.127717</td>\n",
              "      <td>0.059589</td>\n",
              "      <td>0.121411</td>\n",
              "      <td>0.113867</td>\n",
              "      <td>0.129190</td>\n",
              "      <td>0.195825</td>\n",
              "      <td>0.155137</td>\n",
              "      <td>0.069726</td>\n",
              "      <td>0.285806</td>\n",
              "      <td>0.162337</td>\n",
              "      <td>0.343537</td>\n",
              "      <td>0.424151</td>\n",
              "      <td>0.269920</td>\n",
              "      <td>0.303148</td>\n",
              "      <td>0.461980</td>\n",
              "      <td>0.077774</td>\n",
              "      <td>0.130569</td>\n",
              "      <td>0.103565</td>\n",
              "      <td>0.032949</td>\n",
              "      <td>0.036644</td>\n",
              "      <td>0.027407</td>\n",
              "      <td>0.045513</td>\n",
              "      <td>0.009326</td>\n",
              "      <td>0.034407</td>\n",
              "      <td>0.086568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070331</td>\n",
              "      <td>0.094355</td>\n",
              "      <td>0.158070</td>\n",
              "      <td>0.110748</td>\n",
              "      <td>0.155452</td>\n",
              "      <td>0.175475</td>\n",
              "      <td>0.333532</td>\n",
              "      <td>0.200676</td>\n",
              "      <td>0.103231</td>\n",
              "      <td>0.065915</td>\n",
              "      <td>0.064129</td>\n",
              "      <td>0.097510</td>\n",
              "      <td>0.079041</td>\n",
              "      <td>0.076799</td>\n",
              "      <td>0.087420</td>\n",
              "      <td>0.095940</td>\n",
              "      <td>0.151782</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>0.528912</td>\n",
              "      <td>0.669710</td>\n",
              "      <td>0.257686</td>\n",
              "      <td>0.209737</td>\n",
              "      <td>0.109770</td>\n",
              "      <td>0.130463</td>\n",
              "      <td>0.121519</td>\n",
              "      <td>0.234291</td>\n",
              "      <td>0.268331</td>\n",
              "      <td>0.377868</td>\n",
              "      <td>0.122994</td>\n",
              "      <td>0.069535</td>\n",
              "      <td>0.081004</td>\n",
              "      <td>0.024437</td>\n",
              "      <td>0.151519</td>\n",
              "      <td>0.105631</td>\n",
              "      <td>0.150209</td>\n",
              "      <td>0.159187</td>\n",
              "      <td>0.238096</td>\n",
              "      <td>0.254572</td>\n",
              "      <td>0.321196</td>\n",
              "      <td>0.208404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scallion</th>\n",
              "      <td>0.051006</td>\n",
              "      <td>0.060547</td>\n",
              "      <td>0.007723</td>\n",
              "      <td>0.043176</td>\n",
              "      <td>0.107297</td>\n",
              "      <td>0.070880</td>\n",
              "      <td>0.032464</td>\n",
              "      <td>0.194061</td>\n",
              "      <td>0.399926</td>\n",
              "      <td>0.640449</td>\n",
              "      <td>0.717322</td>\n",
              "      <td>0.587431</td>\n",
              "      <td>0.426106</td>\n",
              "      <td>0.181480</td>\n",
              "      <td>0.107005</td>\n",
              "      <td>0.221869</td>\n",
              "      <td>0.444344</td>\n",
              "      <td>0.504269</td>\n",
              "      <td>0.482544</td>\n",
              "      <td>0.206579</td>\n",
              "      <td>0.404794</td>\n",
              "      <td>0.456223</td>\n",
              "      <td>0.380109</td>\n",
              "      <td>0.181450</td>\n",
              "      <td>0.229923</td>\n",
              "      <td>0.159732</td>\n",
              "      <td>0.183573</td>\n",
              "      <td>0.236532</td>\n",
              "      <td>0.205033</td>\n",
              "      <td>0.091719</td>\n",
              "      <td>0.262473</td>\n",
              "      <td>0.495560</td>\n",
              "      <td>0.368810</td>\n",
              "      <td>0.287597</td>\n",
              "      <td>0.300988</td>\n",
              "      <td>0.189225</td>\n",
              "      <td>0.347260</td>\n",
              "      <td>0.653368</td>\n",
              "      <td>0.279740</td>\n",
              "      <td>0.371230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294638</td>\n",
              "      <td>0.390857</td>\n",
              "      <td>0.347041</td>\n",
              "      <td>0.164755</td>\n",
              "      <td>0.185333</td>\n",
              "      <td>0.123727</td>\n",
              "      <td>0.113339</td>\n",
              "      <td>0.283336</td>\n",
              "      <td>0.342218</td>\n",
              "      <td>0.308409</td>\n",
              "      <td>0.504854</td>\n",
              "      <td>0.325888</td>\n",
              "      <td>0.415768</td>\n",
              "      <td>0.441405</td>\n",
              "      <td>0.228497</td>\n",
              "      <td>0.241685</td>\n",
              "      <td>0.234863</td>\n",
              "      <td>0.360908</td>\n",
              "      <td>0.107052</td>\n",
              "      <td>0.058542</td>\n",
              "      <td>0.122882</td>\n",
              "      <td>0.306668</td>\n",
              "      <td>0.302546</td>\n",
              "      <td>0.231972</td>\n",
              "      <td>0.389140</td>\n",
              "      <td>0.251242</td>\n",
              "      <td>0.292820</td>\n",
              "      <td>0.153496</td>\n",
              "      <td>0.280529</td>\n",
              "      <td>0.513091</td>\n",
              "      <td>0.496605</td>\n",
              "      <td>0.504847</td>\n",
              "      <td>0.321320</td>\n",
              "      <td>0.430952</td>\n",
              "      <td>0.346998</td>\n",
              "      <td>0.209783</td>\n",
              "      <td>0.162319</td>\n",
              "      <td>0.150318</td>\n",
              "      <td>0.214683</td>\n",
              "      <td>0.192512</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 255 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     <s>   mix</w>   the</w>  ...     a</w>   few</w>         c\n",
              "plain yogurt    0.120862  0.198283  0.111036  ...  0.072877  0.220816  0.241750\n",
              "chicken breast  0.225498  0.381452  0.658146  ...  0.522232  0.243305  0.357334\n",
              "white onion     0.602634  0.359718  0.223095  ...  0.254572  0.321196  0.208404\n",
              "scallion        0.051006  0.060547  0.007723  ...  0.150318  0.214683  0.192512\n",
              "\n",
              "[4 rows x 255 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf_INEKC-HxK",
        "colab_type": "text"
      },
      "source": [
        "# NutriScore calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1v2Trv1_Omm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Data/PP_recipes.csv', engine='c')\n",
        "for col in ['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']:\n",
        "    df[col] = df[col].agg(eval)\n",
        "df.to_pickle('DataTemp/recipes.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJHKFgY9J78A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('DataModified/PP_recipes.csv', engine='c')\n",
        "#RAW_recipes_modified.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzaPXzl1DQgp",
        "colab_type": "text"
      },
      "source": [
        "changing PP_Recipes data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GTjpZHBQC2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read two input files\n",
        "#df.to_pickle(\"Data/RAW_recipes_modified.pkl\")\n",
        "df_recipes_raw_mod = pd.read_pickle(\"Data/RAW_recipes_modified.pkl\")\n",
        "df_pp_rec = pd.read_csv('Data/PP_recipes.csv', engine='c')\n",
        "for col in ['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']:\n",
        "    df_pp_rec[col] = df_pp_rec[col].agg(eval)\n",
        "\n",
        "# selecting the relevant columns (id + nutriscore)\n",
        "\n",
        "cols = ['id','nutriscore']\n",
        "df_rec_raw_temp = df_recipes_raw_mod[cols]\n",
        "\n",
        "#merge by key (id)\n",
        "result = pd.merge(df_pp_rec,df_rec_raw_temp, on='id')\n",
        "#drop old column (calorie level)\n",
        "result = result.drop(['calorie_level'],axis=1)\n",
        "#rename new column\n",
        "result = result.rename(columns={\"nutriscore\": \"calorie_level\"})\n",
        "#save new DF to file\n",
        "result.to_csv('DataTemp/PP_recipes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mRVWITdwO7l",
        "colab_type": "text"
      },
      "source": [
        "NutriScore functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhemzKUq9kPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "341907ba-e675-471c-d603-cb47669fe645"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "  def convert_dflist_to_list (feat):\n",
        "    f_list = []\n",
        "    temp_str = feat.split(\"[\")[1].split(\"]\")[0].split(\",\")\n",
        "    for item in temp_str:\n",
        "      C = int(item)\n",
        "      f_list.append(C)\n",
        "    return f_list\n",
        "\n",
        "\n",
        "\n",
        "def PDV_to_grams(val, max_val):\n",
        "  return (max_val * val / 100)\n",
        "  \n",
        "def nutri_score(val, scale):\n",
        "  i = 0\n",
        "  while (i < 10) :\n",
        "    if val < scale[i]:\n",
        "    #  print (\"in if: i=\",i,\"val\",val,\"is smaller than scale:\",scale[i])\n",
        "      return (i)\n",
        "    else:\n",
        "      i +=1\n",
        "  return (i)  \n",
        "      \n",
        "\n",
        "def calc_nutrition_grade(nutri_feat):\n",
        " # zeros = np.zeros(11)\n",
        "  nutri_list = []\n",
        "  temp_str = nutri_feat.split(\"[\")[1].split(\"]\")[0].split(\",\")\n",
        "  for item in temp_str:\n",
        "      C = float(item)\n",
        "      nutri_list.append(C)\n",
        "  \n",
        "  #print (nutri_list)\n",
        "  max_val_list = [2000, 65, 31, 2.3, 50, 20, 300]\n",
        "  #1: cals 2: fats 3:sugar 4: sodium 5. protein 6: saturated fat 7: carbohydrates\n",
        "  cals, tot_fats_dv, sugar_dv, sodium_dv, protein_dv, satur_fat_dv, carbons_dv = [nutri_list[i] for i in range (7)]\n",
        "  max_cals, max_tot_fats, max_sugar, max_sodium, max_protein, max_satur_fat, max_carbons = [nutri_list[i] for i in range (7)]\n",
        "  tot_fats = PDV_to_grams(tot_fats_dv, max_tot_fats)\n",
        "  sugar = PDV_to_grams(sugar_dv, max_sugar)\n",
        "  sodium = PDV_to_grams(sodium_dv, max_sodium)\n",
        "  satur_fat = PDV_to_grams(satur_fat_dv, max_satur_fat)\n",
        "  \n",
        "  #positives: protein\n",
        "  #negatives: sugar, calories, fatty acids, sodium\n",
        "  #print (\"cals\",cals,\"fats\",satur_fat,\"sugar\",sugar,\"sodium\",sodium)\n",
        "  calories_scale = np.array([335,670,1005,1340,1675,2010,2345,2680,3015,3350])\n",
        "  sugars_scale = np.array([4.5,9,13.5,18,22.5,27,31,36,40,45])\n",
        "  fats_scale = np.asarray([i for i in range (1,11)])\n",
        "  sodium_scale = np.array([0.09,0.18,0.27,0.36,0.45,0.54,0.63,0.72,0.81,0.9])\n",
        "\n",
        "  a = nutri_score(cals, calories_scale)\n",
        "  b = nutri_score(sugar, sugars_scale)\n",
        "  c = nutri_score(satur_fat, fats_scale)\n",
        "  d = nutri_score(sodium, sodium_scale)\n",
        "\n",
        "  final_score = [a,b,c,d]\n",
        "  result = np.zeros((4,11))\n",
        "  data = np.array(final_score)\n",
        "  encoded = to_categorical(data,dtype='int32')#.reshape(1,44)\n",
        "  result [:encoded.shape[0],:encoded.shape[1]] = encoded\n",
        "  result = result.reshape(1,44).astype(int)\n",
        "  return result\n",
        "'''\n",
        "#MAIN\n",
        "df = pd.read_csv('Data/RAW_recipes.csv', engine='c')\n",
        "samples  = df['nutrition']\n",
        "decoded = []\n",
        "for g in range (len(samples)):\n",
        "   # print (\"new sample\")\n",
        "    t = samples.iloc[g]\n",
        "    f = calc_nutrition_grade(t)\n",
        "   # decoded.append(f)\n",
        "#print (decoded)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#MAIN\\ndf = pd.read_csv(\\'Data/RAW_recipes.csv\\', engine=\\'c\\')\\nsamples  = df[\\'nutrition\\']\\ndecoded = []\\nfor g in range (len(samples)):\\n   # print (\"new sample\")\\n    t = samples.iloc[g]\\n    f = calc_nutrition_grade(t)\\n   # decoded.append(f)\\n#print (decoded)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHkg8Bo8qFai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "samples  = df['nutrition']\n",
        "temp = []\n",
        "for g in range (len(samples)):\n",
        "    t = samples.iloc[g]\n",
        "    f = calc_nutrition_grade(t)\n",
        "    temp.append(f)\n",
        "#trying to modified original recipes file\n",
        "temp_arr = np.asarray(temp)\n",
        "temp_arr = temp_arr.reshape(len(temp_arr),44)\n",
        "print (temp_arr.shape)\n",
        "temp_l = temp_arr.tolist()\n",
        "df_temp = pd.DataFrame({'nutri_encoded':temp_l})\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df_temp.reset_index(drop=True,inplace=True)\n",
        "result = pd.concat([df,df_temp],axis=1)\n",
        "result.head(10)\n",
        "df_m = pd.merge(rec,result,how='inner',on='id')\n",
        "rec_col = rec.columns\n",
        "all_col = df_m.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT6CR5934DlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_m = df_m.drop(columns=['name', 'minutes','techniques','contributor_id', 'submitted', 'tags', 'nutrition', 'n_steps', 'steps','description', 'ingredients', 'n_ingredients'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMm4_B8u5oJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_m = df_m.rename(columns={'nutri_encoded':'techniques'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wIH30Ft_50C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OK!\n",
        "df_m.to_csv(\"Data/modified_PP_recipes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWwsuwAUj9u7",
        "colab_type": "text"
      },
      "source": [
        "# NutriVecs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KnW0tbUuMdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users_items = users['items'] #slice only items columns. each row belongs to diffenet user\n",
        "nutrivecs = [] #this will eventually keep whole nutrivecs to replace with techniques\n",
        "for g in range (len(users_items)):\n",
        "  #for each user in samples we need to calculated nutrivector (sum)\n",
        "  item_list = users_items.iloc[g] #take a users' items: this is a string\n",
        "  #print (len(u_items))\n",
        "  #item_list = convert_dflist_to_list(u_items) #produce list object of items\n",
        "  tech_l = [] #this is not really techniques, just a list to keep users' \"techniques\" - nutrivecs\n",
        "  #nutri_vec = []\n",
        "  for item in item_list: #for each item (rec) in user items list\n",
        "  #print (item)\n",
        "    rslt_df = rec[rec['i'] == item] #find \"techniques\" ohv belongs to this specific item=reciepe\n",
        "    tech_l.append(rslt_df['techniques'].tolist())\n",
        "  tech_arr = np.asarray(tech_l) #brings to array shape to fix dimensions\n",
        "  tech_arr = tech_arr.reshape(len(tech_arr),44) #fix dimension\n",
        "  nutri_vec = tech_arr.sum(axis=0).tolist()\n",
        "  nutrivecs.append(nutri_vec)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Jt7ZOakXBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77eab8f1-c64b-428f-fbe9-e327ddfd9074"
      },
      "source": [
        "temp_arr = np.asarray(nutrivecs)\n",
        "temp_arr = temp_arr.reshape(len(temp_arr),44)\n",
        "print (temp_arr.shape)\n",
        "temp_l = temp_arr.tolist()\n",
        "df_nutri_temp = pd.DataFrame({'nutrivec':temp_l})\n",
        "users.reset_index(drop=True,inplace=True)\n",
        "df_nutri_temp.reset_index(drop=True,inplace=True)\n",
        "result = pd.concat([users,df_nutri_temp],axis=1)\n",
        "result.to_pickle('Data/modified_user_rep.pkl')\n",
        "result = result.drop(columns=['techniques'])\n",
        "result = result.rename(columns={'nutrivec':'techniques'})\n",
        "result.to_pickle('DataTempCal/user_rep.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25076, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81TWyfW_iwv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "01f8c60f-3aa2-4bab-ca16-aeb361660a8d"
      },
      "source": [
        "'''\n",
        "I have users items (recs) in u_items. so for each recipe in u_items, i ran over recipes table.\n",
        "i extract the techs (encoded as ohv), receive final sparse tech_matrixs for all users' recipes.\n",
        "than i sum them, and got one summerize vector of tech. I compare it to tech vector in users table \n",
        "to ensure we have the same values.\n",
        "'''\n",
        "\n",
        "item_list = convert_dflist_to_list(u_items)\n",
        "\n",
        "tech_l = []\n",
        "for item in item_list:\n",
        "  #print (item)\n",
        "  rslt_df = rec[rec['i'] == item]\n",
        "  tech_l.append(rslt_df['techniques'].tolist())\n",
        "tech_arr = np.asarray(tech_l)\n",
        "tech_arr = tech_arr.reshape(len(tech_arr),58)\n",
        "print (tech_arr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[122140, 77036, 156817, 76957, 68818, 155600, 15142, 107484, 141253, 161084, 38511, 97459, 71971, 139141, 71237, 47107, 155789, 5904, 150772, 128425, 137945, 138873, 132276, 39503, 95552, 4446, 90037, 130117, 46218, 138166, 68243, 78551, 111427, 144656, 134610, 87638, 102591, 0, 65028]\n",
            "(39, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzW9Y2wdbVyk",
        "colab_type": "text"
      },
      "source": [
        "# Create 50K interactions training file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFN83qCNbxWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "b374a646-51a8-445d-9370-acdf0f9d5010"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "int_df = pd.read_csv(\"Data/interactions_train.csv\",nrows=100)\n",
        "int_df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>date</th>\n",
              "      <th>rating</th>\n",
              "      <th>u</th>\n",
              "      <th>i</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2046</td>\n",
              "      <td>4684</td>\n",
              "      <td>2000-02-25</td>\n",
              "      <td>5.0</td>\n",
              "      <td>22095</td>\n",
              "      <td>44367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  recipe_id        date  rating      u      i\n",
              "0     2046       4684  2000-02-25     5.0  22095  44367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farlN_JvdG0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "237b5f61-145b-4ad8-e208-20aa09999db2"
      },
      "source": [
        "int_df.groupby('recipe_id')['user_id'].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "recipe_id\n",
              "100      1\n",
              "164      1\n",
              "191      1\n",
              "278      1\n",
              "350      1\n",
              "        ..\n",
              "9378     1\n",
              "9430     1\n",
              "13307    1\n",
              "48296    1\n",
              "51964    1\n",
              "Name: user_id, Length: 98, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0K4MjjHdXba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "35051404-3838-4385-8222-82ef938c7feb"
      },
      "source": [
        "df = pd.read_csv(\"Data/interactions_train.csv\")\n",
        "#picking users that interact with 30 to 50 recipes\n",
        "filtered_df = df.groupby('user_id').filter(lambda s: s.recipe_id.count() > 30 and s.recipe_id.count() < 50)\n",
        "filtered_df.to_pickle(\"DataTemp50K/interactions_train.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of         user_id  recipe_id        date  rating      u       i\n",
              "13         2178       3704  2000-10-30     3.0   6065    3172\n",
              "14         2178       4366  2000-11-04     5.0   6065   50924\n",
              "19         2695        350  2001-01-19     1.0   9204   13543\n",
              "54         2178       5478  2001-05-24     3.0   6065  135342\n",
              "117        1634       8909  2001-07-02     3.0   7299   35059\n",
              "...         ...        ...         ...     ...    ...     ...\n",
              "698777   885024     102833  2018-11-16     5.0   9891   26175\n",
              "698781   163077     243729  2018-11-17     5.0   3485   72440\n",
              "698791  1580637     329676  2018-11-21     3.0  12999   91046\n",
              "698835   536962     122554  2018-12-03     5.0   9244   60659\n",
              "698894   117501     529600  2018-12-17     5.0  10368   18120\n",
              "\n",
              "[48336 rows x 6 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIRfFiiftUtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_df.to_pickle(\"DataTemp50K/interactions_train.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}